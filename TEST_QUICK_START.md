# üöÄ Quick Test - Valider le Pipeline en 5 minutes

**Objectif:** V√©rifier que le pipeline ETL fonctionne de bout en bout

**Dur√©e:** ~5 minutes

---

## ‚úçÔ∏è √âtape 1: Cr√©er des Fichiers de Test

### 1.1 Cr√©er les dossiers

```bash
# Sur Windows (PowerShell ou cmd)
mkdir -p "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\raw\isavigne\ventes_lignes"
mkdir -p "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\raw\isavigne\clients"
mkdir -p "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\raw\isavigne\produits"
```

### 1.2 Cr√©er fichier ventes_lignes_2025-12-27.csv

**Chemin:** `C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\raw\isavigne\ventes_lignes\ventes_lignes_2025-12-27.csv`

**Contenu:**
```csv
client_code,date_livraison,produit_label,qty_line,pu_ht,mt_ht,mt_ttc,marge,document_type,document_no,article,email,code_postal,ville
CL001,2025-12-27,Cremant Alsace Extra Brut,1,8.50,8.50,10.20,2.00,VENTE,V0001,CREMANT,jean@test.fr,67000,Strasbourg
CL002,2025-12-27,Gewurztraminer Vendanges Tardives,2,15.00,30.00,36.00,8.00,VENTE,V0002,GEWURZ,marie@test.fr,75000,Paris
CL003,2025-12-27,Riesling Alsace,1,10.00,10.00,12.00,3.00,VENTE,V0003,RIESLING,pierre@test.fr,13000,Marseille
CL001,2025-12-27,Gewurztraminer VT,1,15.00,15.00,18.00,4.00,VENTE,V0004,GEWURZ2,jean@test.fr,67000,Strasbourg
```

### 1.3 Cr√©er fichier clients_2025-12-27.csv

**Chemin:** `C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\raw\isavigne\clients\clients_2025-12-27.csv`

**Contenu:**
```csv
client_code,nom,prenom,email,telephone,adresse,code_postal,ville,pays
CL001,Dupont,Jean,jean@test.fr,0123456789,1 rue de l'Exemple,67000,Strasbourg,France
CL002,Martin,Marie,marie@test.fr,0987654321,2 avenue de Paris,75000,Paris,France
CL003,Bernard,Pierre,pierre@test.fr,0456789123,3 boulevard Marseille,13000,Marseille,France
```

### 1.4 Cr√©er fichier produits_2025-12-27.csv

**Chemin:** `C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\raw\isavigne\produits\produits_2025-12-27.csv`

**Contenu:**
```csv
produit,article,millesime,famille_crm,sous_famille,macro_categorie,prix_ttc,price_band,premium_tier
Cremant Alsace Extra Brut,CREMANT,2023,Alsace,Effervescents,Aperitif,10.20,10-15,Standard
Gewurztraminer Vendanges Tardives,GEWURZ,2022,Alsace,Blancs,Premium,36.00,30-40,Premium
Gewurztraminer Vendanges Tardives,GEWURZ2,2021,Alsace,Blancs,Premium,36.00,30-40,Premium
Riesling Alsace,RIESLING,2023,Alsace,Blancs,Standard,12.00,10-15,Standard
```

---

## üéØ √âtape 2: Lancer le Pipeline

### 2.1 Ouvrir Terminal

```bash
# Ouvrir PowerShell ou CMD
# Aller au dossier du projet
cd C:\Windows\System32\crm-reco-platform
```

### 2.2 Lancer le Pipeline Complet

```bash
python etl/main.py
```

### 2.3 Attendre les R√©sultats

Tu verras:
```
======================================================================
  üìä D√âMARRAGE PIPELINE ETL COMPLET
======================================================================

üîµ √âTAPE 1/3: INGESTION RAW ‚Üí STAGING
...
üîµ √âTAPE 2/3: TRANSFORMATION STAGING ‚Üí CURATED
...
üîµ √âTAPE 3/3: CHARGEMENT CURATED ‚Üí PostgreSQL
...

üåü PIPELINE COMPLET - R√âSUM√â FINAL
======================================================================
  ‚úÖ SUCC√àS COMPLET - Pipeline ETL Fonctionnel! üöÄ
======================================================================
```

---

## üîç √âtape 3: V√©rifier les R√©sultats

### 3.1 V√©rifier les Fichiers G√©n√©r√©s

```bash
# Fichiers en STAGING
dir "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\staging\"
# Doit contenir: ventes_lignes_raw_*.csv, clients_raw_*.csv, produits_raw_*.csv

# Fichiers CURATED
dir "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\curated\"
# Doit contenir: VENTES_LIGNES_curated_*.csv, CLIENTS_curated_*.csv, etc.

# Logs d'ex√©cution
dir "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\logs\"
# Doit contenir: run_*.log
```

### 3.2 V√©rifier dans PostgreSQL

**Option 1: Ligne de commande**

```bash
# V√©rifier les donn√©es dans PostgreSQL
docker exec crm-postgres psql -U crm_user -d crm_reco -c "SELECT COUNT(*) as total FROM etl.ventes_lignes;"

# Doit afficher: total
#                4     (4 lignes de ventes de test)
```

**Option 2: Depuis pgAdmin (interface web)**

```
http://localhost:5050
login: admin@example.com
password: admin

Servers > crm-reco > Databases > crm_reco > Schemas > etl > Tables
  - ventes_lignes (4 rows)
  - clients (3 rows)
  - produits (4 rows)
```

### 3.3 Lire les Logs

```bash
# Fichier de log principal
type "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\logs\run_*.log"

# Tu verras quelque chose comme:
# 2025-12-27 16:00:15 - root - INFO - === INGESTION RAW ===
# 2025-12-27 16:00:15 - root - INFO - D√©tect√© 3 fichier(s)
# 2025-12-27 16:00:20 - root - INFO - ‚úÖ Succ√®s: 4 lignes en staging
```

---

## ‚úÖ Checklist de Succ√®s

- [ ] Fichiers de test cr√©√©s dans `exports/raw/isavigne/`
- [ ] Pipeline lanc√©: `python etl/main.py`
- [ ] Message "‚úÖ SUCC√àS COMPLET" affich√©
- [ ] Fichiers STAGING cr√©√©s (`exports/staging/`)
- [ ] Fichiers CURATED cr√©√©s (`exports/curated/`)
- [ ] Logs g√©n√©r√©s (`exports/logs/`)
- [ ] PostgreSQL contient les donn√©es (4 ventes, 3 clients, 4 produits)
- [ ] Pas d'erreurs dans les logs

---

## üêõ Troubleshooting

### "ModuleNotFoundError: No module named 'pandas'"

```bash
# Installer les d√©pendances
pip install -r requirements.txt
```

### "Connexion PostgreSQL √©chou√©e"

```bash
# V√©rifier que PostgreSQL est lanc√©
docker-compose ps postgres

# Relancer si besoin
docker-compose restart postgres

# Attendre 5 secondes et r√©essayer
```

### "Dossiers RAW introuvables"

```bash
# Cr√©er la structure compl√®te
mkdir -p "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\raw\isavigne\{ventes_lignes,clients,produits}"
```

### "Aucun fichier CURATED d√©tect√©"

Le fichier CSV doit √™tre bien format√©:
- Colonnes en minuscules avec underscores
- Valeurs num√©riques avec point (pas de virgule)
- Dates au format YYYY-MM-DD
- V√©rifier les logs pour les colonnes attendues

---

## üëÄ Pr√©cisions Import√©es de Test

### Doublons Simul√©s

Le fichier de test contient:
- 1 doublon dans les ventes (CL001 avec 2 produits diff√©rents)
- Tu verras: "‚ö†Ô∏è Doublons d√©tect√©s: 0" (car les produits sont diff√©rents)

### Transformations Appliqu√©es

Le pipeline va:
1. Normaliser les codes clients (trim, uppercase)
2. Cr√©er produit_key (de "Cremant Alsace Extra Brut" ‚Üí "CREMANT ALSACE EXTRA BRUT")
3. Cr√©er document_id (de document_no et client_code)
4. Calculer qty_unit (conversion articles en unit√©s)

### V√©rifier une Ligne Transform√©e

```bash
# Ouvrir le fichier CURATED
type "C:\Users\Valentin\Desktop\CRM_Ruhlmann\exports\curated\VENTES_LIGNES_curated_*.csv"

# Tu verras des colonnes suppl√©mentaires:
#   - produit_key (normalis√©)
#   - document_id (cr√©√©)
#   - qty_unit (converti)
```

---

## üîó Donn√©es Charg√©es en Base

### Table: etl.ventes_lignes

```sql
SELECT * FROM etl.ventes_lignes LIMIT 5;

-- Doit retourner 4 lignes avec:
--   client_code: CL001, CL002, CL003, CL001
--   produit_key: CREMANT ALSACE EXTRA BRUT, etc.
--   mt_ht: 8.50, 30.00, 10.00, 15.00
```

### Table: etl.clients

```sql
SELECT client_code, nom, email FROM etl.clients;

-- Doit retourner 3 lignes:
--   CL001, Dupont, jean@test.fr
--   CL002, Martin, marie@test.fr
--   CL003, Bernard, pierre@test.fr
```

### Table: etl.produits

```sql
SELECT produit_key, prix_ttc FROM etl.produits;

-- Doit retourner 4 lignes de produits
```

---

## üåü Prochaines √âtapes (Apr√®s Test)

1. **Tester avec donn√©es r√©elles iSaVigne**
   - Exporter vraies donn√©es iSaVigne
   - Placer dans `exports/raw/isavigne/`
   - Lancer pipeline

2. **Valider la qualit√©**
   - V√©rifier les transformations
   - Consulter les logs pour anomalies

3. **Configurer Power Automate Desktop**
   - Automatiser les exports iSaVigne
   - Scheduler l'ex√©cution hebdomadaire

4. **Int√©grer Brevo**
   - Cr√©er module de synchronisation
   - Templates d'emails

---

## üã°Ô∏è Architecture Test√©e

```
RAW files (Test)
    ‚Üì
ETL Pipeline (ingest ‚Üí transform ‚Üí load)
    ‚Üì
STAGING files (Test files with timestamp)
    ‚Üì
CURATED files (Transformed & normalized)
    ‚Üì
PostgreSQL (Data loaded)
    ‚úì VERIFY with SQL queries
```

---

## üìù Notes

- Les fichiers de test sont **minimalistes** mais complets
- Le pipeline applique **les m√™mes transformations** que les vraies donn√©es
- Les logs **tracent chaque √©tape** pour debug facile
- Les doublons sont **automatiquement d√©tect√©s et supprim√©s**
- PostgreSQL **accepte les donn√©es imm√©diatement**

---

**Si tout fonctionne ‚úÖ, le pipeline est pr√™t pour les donn√©es r√©elles!** üöÄ

*Dur√©e test: ~5 minutes*  
*Dur√©e r√©elles donn√©es: variable selon volume*
